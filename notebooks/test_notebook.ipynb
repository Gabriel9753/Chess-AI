{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ChessDataset import ChessDataset\n",
    "from ChessNet import Net\n",
    "from torch.optim import lr_scheduler\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from util import get_device, load_data, get_datalaoder\n",
    "\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "N_TRAIN_EXAMPLES = 20000\n",
    "N_VALID_EXAMPLES = 5000\n",
    "\n",
    "DEVICE = get_device()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 4)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 13 * 8 * 8\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 32, 1024)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.1, 0.4)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, 1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\", \"AdamW\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=N_TRAIN_EXAMPLES, epochs=EPOCHS)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_datalaoder(chess_data, BATCH_SIZE)\n",
    "    val_loss = 999999999999\n",
    "    # Training of the model.\n",
    "    with tqdm(total=EPOCHS, desc=\"Training\") as pbar:\n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                # Limiting training data for faster epochs.\n",
    "                if batch_idx * BATCH_SIZE >= N_TRAIN_EXAMPLES:\n",
    "                    break\n",
    "\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data.float())\n",
    "                loss = criterion(output, target)\n",
    "                if batch_idx % 100 == 0:\n",
    "                    pbar.set_postfix({'Sample': f'{batch_idx*BATCH_SIZE}/{N_TRAIN_EXAMPLES}', 'Train-Loss': f'{loss.item()/BATCH_SIZE:.5f}'})\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            # Validation of the model.\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                    # Limiting validation data.\n",
    "                    if batch_idx * BATCH_SIZE >= N_VALID_EXAMPLES:\n",
    "                        break\n",
    "                    data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                    output = model(data.float())\n",
    "                    loss = criterion(output, target)\n",
    "                    val_loss += loss.item()\n",
    "                    if batch_idx % 100 == 0:\n",
    "                        pbar.set_postfix({'Val_sample': f'{batch_idx*BATCH_SIZE}/{N_VALID_EXAMPLES}', 'Val-Loss': f'{loss.item():.5f}', 'Val-Loss_avg': f'{val_loss/(batch_idx+1):.5f}'})\n",
    "\n",
    "            val_loss = val_loss / N_VALID_EXAMPLES\n",
    "\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            # Handle pruning based on the intermediate value.\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "            pbar.update(1)\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-11 23:50:05,032]\u001b[0m A new study created in memory with name: no-name-b2db823f-9dfd-450d-a34e-ce46074f5c9e\u001b[0m\n",
      "Training: 100%|██████████| 20/20 [00:17<00:00,  1.14it/s, Val_sample=0/5000, Val-Loss=31.04224, Val-Loss_avg=31.04224]\n",
      "\u001b[32m[I 2022-11-11 23:50:25,738]\u001b[0m Trial 0 finished with value: 0.4564515966415405 and parameters: {'n_layers': 1, 'n_units_l0': 218, 'dropout_l0': 0.25787537793675763, 'optimizer': 'SGD', 'lr': 3.4760206044649325e-05}. Best is trial 0 with value: 0.4564515966415405.\u001b[0m\n",
      "Training: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s, Val_sample=0/5000, Val-Loss=3.78852, Val-Loss_avg=3.78852] \n",
      "\u001b[32m[I 2022-11-11 23:50:45,162]\u001b[0m Trial 1 finished with value: 0.26067745633125305 and parameters: {'n_layers': 2, 'n_units_l0': 351, 'dropout_l0': 0.3904752189894659, 'n_units_l1': 628, 'dropout_l1': 0.37282285879269417, 'optimizer': 'SGD', 'lr': 0.04522108580639937}. Best is trial 1 with value: 0.26067745633125305.\u001b[0m\n",
      "Training: 100%|██████████| 20/20 [00:17<00:00,  1.16it/s, Val_sample=0/5000, Val-Loss=6.55072, Val-Loss_avg=6.55072]\n",
      "\u001b[32m[I 2022-11-11 23:51:02,597]\u001b[0m Trial 2 finished with value: 0.492558261680603 and parameters: {'n_layers': 1, 'n_units_l0': 468, 'dropout_l0': 0.35048811498949695, 'optimizer': 'SGD', 'lr': 9.232000516144439e-05}. Best is trial 1 with value: 0.26067745633125305.\u001b[0m\n",
      "Training: 100%|██████████| 20/20 [00:19<00:00,  1.03it/s, Val_sample=0/5000, Val-Loss=9.08064, Val-Loss_avg=9.08064]  \n",
      "\u001b[32m[I 2022-11-11 23:51:22,184]\u001b[0m Trial 3 finished with value: 0.22983099493980408 and parameters: {'n_layers': 1, 'n_units_l0': 226, 'dropout_l0': 0.3232978290769121, 'optimizer': 'RMSprop', 'lr': 0.0004750211221252809}. Best is trial 3 with value: 0.22983099493980408.\u001b[0m\n",
      "Training: 100%|██████████| 20/20 [00:20<00:00,  1.05s/it, Val_sample=0/5000, Val-Loss=14.53805, Val-Loss_avg=14.53805]\n",
      "\u001b[32m[I 2022-11-11 23:51:43,373]\u001b[0m Trial 4 finished with value: 0.37273129069805144 and parameters: {'n_layers': 2, 'n_units_l0': 823, 'dropout_l0': 0.22268160532354017, 'n_units_l1': 224, 'dropout_l1': 0.11643485722566907, 'optimizer': 'Adam', 'lr': 0.0003499186573909289}. Best is trial 3 with value: 0.22983099493980408.\u001b[0m\n",
      "Training:  25%|██▌       | 5/20 [00:06<00:19,  1.31s/it, Val_sample=0/5000, Val-Loss=25.17795, Val-Loss_avg=25.17795]\n",
      "\u001b[32m[I 2022-11-11 23:51:50,096]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "Training:  35%|███▌      | 7/20 [00:10<00:19,  1.48s/it, Val_sample=0/5000, Val-Loss=23.95530, Val-Loss_avg=23.95530]\n",
      "\u001b[32m[I 2022-11-11 23:52:00,657]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "Training: 100%|██████████| 20/20 [00:23<00:00,  1.18s/it, Val_sample=0/5000, Val-Loss=6.18523, Val-Loss_avg=6.18523] \n",
      "\u001b[32m[I 2022-11-11 23:52:24,540]\u001b[0m Trial 7 finished with value: 0.2006756387233734 and parameters: {'n_layers': 3, 'n_units_l0': 382, 'dropout_l0': 0.19146414512011245, 'n_units_l1': 439, 'dropout_l1': 0.16513089823718002, 'n_units_l2': 710, 'dropout_l2': 0.15374156984513637, 'optimizer': 'Adam', 'lr': 0.007759080345587955}. Best is trial 7 with value: 0.2006756387233734.\u001b[0m\n",
      "Training:   0%|          | 0/20 [00:00<?, ?it/s, Val_sample=0/5000, Val-Loss=0.40087, Val-Loss_avg=0.40087]\n",
      "\u001b[32m[I 2022-11-11 23:52:25,577]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "Training:   5%|▌         | 1/20 [00:01<00:35,  1.84s/it, Val_sample=0/5000, Val-Loss=24.86561, Val-Loss_avg=24.86561]\n",
      "\u001b[32m[I 2022-11-11 23:52:27,603]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  10\n",
      "  Number of pruned trials:  4\n",
      "  Number of complete trials:  6\n",
      "Best trial:\n",
      "  Value:  0.2006756387233734\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 382\n",
      "    dropout_l0: 0.19146414512011245\n",
      "    n_units_l1: 439\n",
      "    dropout_l1: 0.16513089823718002\n",
      "    n_units_l2: 710\n",
      "    dropout_l2: 0.15374156984513637\n",
      "    optimizer: Adam\n",
      "    lr: 0.007759080345587955\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, values=[0.4564515966415405], datetime_start=datetime.datetime(2022, 11, 11, 23, 50, 5, 34192), datetime_complete=datetime.datetime(2022, 11, 11, 23, 50, 25, 737949), params={'n_layers': 1, 'n_units_l0': 218, 'dropout_l0': 0.25787537793675763, 'optimizer': 'SGD', 'lr': 3.4760206044649325e-05}, distributions={'n_layers': IntDistribution(high=4, log=False, low=1, step=1), 'n_units_l0': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l0': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD', 'AdamW')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.45697897119522096, 1: 0.45694997272491455, 2: 0.45692034797668457, 3: 0.45688678941726685, 4: 0.4568616651535034, 5: 0.45683273706436156, 6: 0.45681643686294554, 7: 0.456786745262146, 8: 0.4567595580101013, 9: 0.45673000860214236, 10: 0.45670562286376953, 11: 0.4566841232299805, 12: 0.4566583287239075, 13: 0.4566314153671265, 14: 0.4565955206871033, 15: 0.45656393499374387, 16: 0.4565400318145752, 17: 0.45651112909317015, 18: 0.4564815763473511, 19: 0.4564515966415405}, trial_id=0, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=1, values=[0.26067745633125305], datetime_start=datetime.datetime(2022, 11, 11, 23, 50, 25, 739016), datetime_complete=datetime.datetime(2022, 11, 11, 23, 50, 45, 162575), params={'n_layers': 2, 'n_units_l0': 351, 'dropout_l0': 0.3904752189894659, 'n_units_l1': 628, 'dropout_l1': 0.37282285879269417, 'optimizer': 'SGD', 'lr': 0.04522108580639937}, distributions={'n_layers': IntDistribution(high=4, log=False, low=1, step=1), 'n_units_l0': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l0': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'n_units_l1': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l1': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD', 'AdamW')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.40198054876327516, 1: 0.41499727535247805, 2: 0.3680918147087097, 3: 0.35628155946731566, 4: 0.30901915044784545, 5: 0.3115786346435547, 6: 0.3026181896209717, 7: 0.2989663197517395, 8: 0.2940480381011963, 9: 0.2725597821235657, 10: 0.2788169855117798, 11: 0.27278291749954225, 12: 0.31163604974746706, 13: 0.26864495906829833, 14: 0.27040500431060793, 15: 0.27632129697799684, 16: 0.26720039277076724, 17: 0.269110576415062, 18: 0.26441782960891724, 19: 0.26067745633125305}, trial_id=1, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=2, values=[0.492558261680603], datetime_start=datetime.datetime(2022, 11, 11, 23, 50, 45, 163458), datetime_complete=datetime.datetime(2022, 11, 11, 23, 51, 2, 597513), params={'n_layers': 1, 'n_units_l0': 468, 'dropout_l0': 0.35048811498949695, 'optimizer': 'SGD', 'lr': 9.232000516144439e-05}, distributions={'n_layers': IntDistribution(high=4, log=False, low=1, step=1), 'n_units_l0': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l0': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD', 'AdamW')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.4943055994987488, 1: 0.4942158591270447, 2: 0.4941218361854553, 3: 0.49403607749938966, 4: 0.4939559121131897, 5: 0.4938777889251709, 6: 0.4938033791542053, 7: 0.49372304382324217, 8: 0.49364264001846314, 9: 0.49355150871276854, 10: 0.49345862188339235, 11: 0.49336736793518066, 12: 0.49329188938140867, 13: 0.49318678512573244, 14: 0.4930813733100891, 15: 0.4929895723342895, 16: 0.4928779167175293, 17: 0.4927723874092102, 18: 0.4926657361984253, 19: 0.492558261680603}, trial_id=2, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=3, values=[0.22983099493980408], datetime_start=datetime.datetime(2022, 11, 11, 23, 51, 2, 598535), datetime_complete=datetime.datetime(2022, 11, 11, 23, 51, 22, 183881), params={'n_layers': 1, 'n_units_l0': 226, 'dropout_l0': 0.3232978290769121, 'optimizer': 'RMSprop', 'lr': 0.0004750211221252809}, distributions={'n_layers': IntDistribution(high=4, log=False, low=1, step=1), 'n_units_l0': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l0': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD', 'AdamW')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.44018208993673325, 1: 0.416314767074585, 2: 0.3957144705295563, 3: 0.37590500869750976, 4: 0.3562810779333115, 5: 0.3365557894706726, 6: 0.3209126747131348, 7: 0.3075418945789337, 8: 0.29342952723503113, 9: 0.28313226828575133, 10: 0.2714402021884918, 11: 0.26528092651367186, 12: 0.26079270610809324, 13: 0.2519037489891052, 14: 0.2443310589313507, 15: 0.2418742404937744, 16: 0.2370488766670227, 17: 0.23387315590381622, 18: 0.23006191663742065, 19: 0.22983099493980408}, trial_id=3, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=4, values=[0.37273129069805144], datetime_start=datetime.datetime(2022, 11, 11, 23, 51, 22, 185009), datetime_complete=datetime.datetime(2022, 11, 11, 23, 51, 43, 372998), params={'n_layers': 2, 'n_units_l0': 823, 'dropout_l0': 0.22268160532354017, 'n_units_l1': 224, 'dropout_l1': 0.11643485722566907, 'optimizer': 'Adam', 'lr': 0.0003499186573909289}, distributions={'n_layers': IntDistribution(high=4, log=False, low=1, step=1), 'n_units_l0': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l0': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'n_units_l1': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l1': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD', 'AdamW')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.4641545189023018, 1: 0.4632283552646637, 2: 0.46145686428546906, 3: 0.45851692643165587, 4: 0.45392598598003386, 5: 0.44841080293655394, 6: 0.4424479990720749, 7: 0.43657971286773684, 8: 0.4314177132129669, 9: 0.4259889235973358, 10: 0.4213333837747574, 11: 0.41670883498191835, 12: 0.4113360058784485, 13: 0.4055368446350098, 14: 0.4003882746219635, 15: 0.39499498856067655, 16: 0.390105877494812, 17: 0.38388160490989687, 18: 0.3786257872581482, 19: 0.37273129069805144}, trial_id=4, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=7, values=[0.2006756387233734], datetime_start=datetime.datetime(2022, 11, 11, 23, 52, 0, 658234), datetime_complete=datetime.datetime(2022, 11, 11, 23, 52, 24, 539957), params={'n_layers': 3, 'n_units_l0': 382, 'dropout_l0': 0.19146414512011245, 'n_units_l1': 439, 'dropout_l1': 0.16513089823718002, 'n_units_l2': 710, 'dropout_l2': 0.15374156984513637, 'optimizer': 'Adam', 'lr': 0.007759080345587955}, distributions={'n_layers': IntDistribution(high=4, log=False, low=1, step=1), 'n_units_l0': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l0': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'n_units_l1': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l1': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'n_units_l2': IntDistribution(high=1024, log=False, low=32, step=1), 'dropout_l2': FloatDistribution(high=0.4, log=False, low=0.1, step=None), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD', 'AdamW')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.3674583136558533, 1: 0.2785318981170654, 2: 0.2545258499145508, 3: 0.24238948154449463, 4: 0.23604048285484314, 5: 0.23835544052124025, 6: 0.23083841948509215, 7: 0.22167752394676207, 8: 0.22538341898918152, 9: 0.2162893298625946, 10: 0.21467299113273622, 11: 0.21411577858924866, 12: 0.2187043095111847, 13: 0.21266931138038636, 14: 0.2213861321926117, 15: 0.20674431357383727, 16: 0.20990276741981506, 17: 0.20511814341545104, 18: 0.20076449298858642, 19: 0.2006756387233734}, trial_id=7, state=TrialState.COMPLETE, value=None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_trials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
